{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always difficult to predict what will happen in the future, but deep neural networks seem to be something that could go either way. First, they could end up like other AI advances in the past that everyone thought were going to stick around, but proved to be less than ideal such as perceptrons and expert systems. They have to take into account lots of different parameters, and overfitting could prove to be a big problem. Additionally, it could easily be that any AI technology that is discovered will not be as amazing as everyone thinks it is in the end. There is a huge distinction between humans and computers, but in AI, people are trying to get computers to come closer and closer to the human ability level. However, they will never quite reach it. Humans are made in God’s image, and machines will never be able to replicate that. That is why it could easily be that most of the AI we discover will turn out to be a “bust” when defined in terms of whether or not it helps machines reach the human level.<br/>",
    "\tOn the other hand, deep neural networks could also be seen as a breakthrough if they are viewed through the lens of not necessarily trying to replicate human intelligence, but just trying to get somewhat closer. Deep learning has opened up the possibility for non-linear problem solving such as the XOR function, and this could lead to many more types of issues getting resolved than what could have been done before with only one layer of computation. With deep neural networks, there are multiple layers between the input and output layers, allowing for a wider range of problems that can be solved and a more accurate classification of information. The networks break things into features based on trends they see and this could prove to be extremely useful in areas such as natural language processing, image processing, audio recognition, and much more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the pdf's in github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Adapted from the class examples'\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 3 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "model.fit(train_images, train_labels, epochs=7, batch_size=50)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
