{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Final Report - Sarah Griffioen",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Vision",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "This project aims to classify Amazon reviews for electronics as either positive, neutral, or negative. In so doing, each product will have its reviews classified, which will be a good indicator as to how good of an electronic each one is. This could help customers decide what product to buy based on what other users have to say about them.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Background",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "I have based my system around the example from chapter 3.5 in the book Deep Learning with Python (Chollet). This example is based around the IMDB movie reviews dataset, and it does a binary classification, deciding whether each review is positive or negative. In this example, they use Keras (Keras), a high-level neural networks API, so I use Keras as well seeing that I model my project off of this chapter. Keras is higher level and easier to use than Tensor Flow as well, so I am using this technology since the project is not necessarily advanced enough to be utilizing the customization that Tensor Flow offers.\nI have made use of pandas, Python Data Analysis Library (Pandas), in my personal version of this sentiment analysis because of the dataset that I am using. I am pulling a dataset from the internet, and it is in json.gz file format. In order to bring it into the system, I chose to read it in using pandas commands. There is a nice pd.read_json(filename) function that worked with the file format that I got from online. Oftentimes, before you can even begin a machine learning project, you have to make sure the data is preprocessed and ready to go. Much of the time spent on the project can be spent in this area, as was the case in my project. I read in the json.gz file as a panda dataframe and manipulated it from there.\nAt the end of the project, there are visual representations of the training and validation loss and accuracy. These are shown in the form of graphs which are presented using matplotlib, a Python 2D plotting library (Matplotlib). This is an easy way to see how the model did without strictly looking at all of the numbers of the output. It allows for easy labelling of x and y axes, and it can easily be used and displayed in Jupyter notebooks, which is what I am using to display my project. Although I did not get this far in my Amazon electronics reviews part of the project, I did get this part running when I worked through the movie reviews project from the chapter on deep learning with Python.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Implementation",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "My implementation of this project is two-fold. First of all, I have Jupyter notebook called “movieReviews” that is the result of me going through the tutorial from chapter 3.5 of the book Deep Learning. Everything in this notebook is running as it should, and there are no errors. The second part of this project is my customization of the movie reviews project. This part is in a Jupyter notebook called “AmazonReviews.” I did not end up getting this network to work fully, but I have parts working along the way.\nFirst of all, in the movie reviews example from the book, the movie reviews have been preprocessed so that they are already converted from a sequence of words into a sequence of integers since words cannot be processed by the system. As usual, they use a training and a testing set to train the model and prevent overfitting. The datasets are all integers after they have been converted from words, but a neural network cannot take a list of integers. Consequently, they use one-hot encoding on the lists by turning them all into vectors made up of ones and zeros. For example, a sequence of [3,5] would become all zeros except the ones in the indices 3 and 5. The architecture they use has two intermediate layers with 16 hidden units each, and a third layer which outputs the scalar prediction (0 for negative, 1 for positive). The intermediate layers’s activation function is “relu,” and the final layer uses a sigmoid activation to output a probability (a score between 0 and 1, indicating how likely the sample is to have the target \"1\", i.e. how likely the review is to be positive). They also use the binary crossentropy loss function, since the model they are using outputs probabilities.\nI modeled the Amazon electronics version off of this, but I changed a few things. First of all, I used the Amazon electronics reviews dataset from the internet, and I had to read it into the system. Before feeding it into the network, I wanted to curate the dataset a little differently than the movie reviews did (they only took the 10,000 most frequently occurring words). I created a function that would calculate the percentage of helpfulness that each review was since there was an attribute for each entry that was called “helpful.” That entry contained information such as “[2,3],” which meant that that particular review was 2/3 helpful. I then added another column to each entry in the json dataset called “perc_help” to hold the floating point value that was the percentage of helpfulness of a review. Then after all that was done, I went through the dataset and deleted all the entries that were below a 50% helpfulness rating.\nBefore the network could be built, there was still more work to be done on the data. In the movie reviews case, there was one command that was used to set up the training and testing data and labels. This command was “(train_data, train_labels), (test_data, test_labels) \u003d imdb.load_data(num_words\u003d10000).” The variables “train_data” and “test_data” are lists of reviews that are really encoded sequences of words (they are lists of integers). The variables “train_labels” and “test_labels” are lists of 0s (negative) and 1s (positive). The argument “num_words\u003d10000” means that only the top 10,000 most frequently occurring words in the training data would be used, and the rest of the data would be deleted so that they could have a smaller dataset to deal with. In the case of the Amazon electronics reviews dataset, I could not set it up this way. Consequently, I figured out how to implement almost all of this manually. I encoded the reviews by using the Tokenizer that Keras provides, and then I split it into training (80%) and testing (20%) datasets. I also manually created a list of 0s and 1s corresponding to the overall ratings of the products. If they were from a 0.0-2.0, they got a 0 for being negative, but if they were from 3.0-5.0, then they got a 1 for being positive. I then split this list of 1s and 0s into the training and testing labels, again by 80% and 20%. The part that I could not implement was limiting it to the 10,000 most frequently occurring words. Because of this, later on I could not vectorize the data, and consequently, the rest of the project does not run properly.\nAlthough the rest of the project cannot run, I still put in some ideas as to how I thought I could have split up the classifications into more categories than positive and negative. There is a comment by the creation of the labels that explains how I could easily change them to be in three categories corresponding to positive, neutral, or negative reviews instead of just two. Later on, the type of activation would have to change as well for the third layer of the architecture. It is using “sigmoid” in the movie reviews example which is typically used for binary output such as a positive or negative review. However, if I were to change it to having three categories, the activation function “softmax” might work better. Softmax accommodates for more categories than simply a binary classification since the output values range between 0 and 1 but always add up to 1. This would allow for the three categories I would be trying to implement. This would also change the loss function since the problem would no longer be binary (binary_crossentropy). Instead, it might work better to use mean squared error, one of the most common loss functions. MSE is the sum of squared distances between the target variable and the predicted values, which does not require a binary problem. I have put these new functions into the code still even though I cannot test to see how it all works.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Results",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Since I could not get to the results section of the Amazon electronics portion of the final project, I will talk about the results I got from the movie reviews portion instead. The model ended up being over-fit, and they combatted this by not training for as long. However, in the end, the results were still pretty good with it having about 88% accuracy. My guess would be that if I got the Amazon electronics one running, it would not perform as well since I took out reviews with a helpfulness rating below a certain point instead of only taking the 10,000 most frequent words. I would think there would be more data to sort through if it was done my way than if it was done by the most frequent words.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Implications",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "This project will help people who are looking to buy the best product from Amazon. Having three categories makes the ratings more reliable and helpful to the customer as well. It will encourage more online presence in relation to shopping and customer interaction with the company online. I do not think it is wrong in any way to base what you buy off of reviews of that product. In fact, it is probably a very wise idea so that you don’t waste time and money ordering what you do not necessarily need.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Bibliography",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Chollet, François. deep-learning-with-python-notebooks: 3.5-classifying-movie-reviews.ipynb, (2017), GitHub repository,\nhttps://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/3.5-classifying-movie-reviews.ipynb\n\nKeras Documentation. keras.io. https://keras.io/\n\nPandas. pydata.org. https://pandas.pydata.org/\n\nMatplotlib. matplotlib.org. https://matplotlib.org/\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}