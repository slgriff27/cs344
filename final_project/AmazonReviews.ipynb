{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Classifying Amazon Electronics Reviews",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Setup",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Load and Train Dataset",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": [
            "         asin   helpful  overall  \\\n1  0528881469  [12, 15]        1   \n2  0528881469  [43, 45]        3   \n3  0528881469   [9, 10]        2   \n5  0594451647    [3, 3]        5   \n9  0594451647    [3, 3]        5   \n\n                                          reviewText   reviewTime  \\\n1  I\u0027m a professional OTR truck driver, and I bou...  11 25, 2010   \n2  Well, what can I say.  I\u0027ve had this unit in m...   09 9, 2010   \n3  Not going to write a long review, even thought...  11 24, 2010   \n5  I am using this with a Nook HD+. It works as d...   01 3, 2014   \n9  This product really works great but I found th...  01 20, 2014   \n\n       reviewerID                   reviewerName  \\\n1   AMO214LNFCEI4                Amazon Customer   \n2  A3N7T0DY83Y4IG                  C. A. Freeman   \n3  A1H8PY3QHMQQA0       Dave M. Shaw \"mack dave\"   \n5  A2JXAZZI9PHK9Z  Billy G. Noland \"Bill Noland\"   \n9  A3BY5KCNQZXV5U                        Matenai   \n\n                                    summary  unixReviewTime  perc_help  \n1                         Very Disappointed      1290643200   0.800000  \n2                            1st impression      1283990400   0.955556  \n3                   Great grafics, POOR GPS      1290556800   0.900000  \n5                   HDMI Nook adapter cable      1388707200   1.000000  \n9  This works great but read the details...      1390176000   1.000000  \n",
            "[311, 1, 356, 703, 41, 5, 2535, 849, 2222, 25, 2, 135, 5, 356, 381, 256, 22352, 1747, 4, 16444, 4, 570, 121, 3, 297, 48, 355, 7, 2487, 4, 1126, 3044, 299, 61, 4, 7, 28, 964, 381, 320, 865, 5, 1463, 299, 87, 36, 3, 143, 6, 5, 154, 576, 244, 48, 210, 1, 64, 164, 75, 7, 25, 16, 445, 17, 5, 64, 10, 1, 356, 1310, 16, 182, 30, 176, 6, 164, 171, 64, 164, 280, 274, 561, 25, 16, 841, 43, 356, 15, 5, 155, 823, 2069, 320, 3787, 68, 1352, 65, 25, 16, 121, 3, 30, 43, 356, 548, 97, 3, 682, 6, 34, 1, 64, 401, 4, 259, 69, 8, 2552, 3, 51, 5, 154, 2831, 86, 2319, 320, 160, 3, 30, 8, 10, 3182, 43, 356, 35, 10, 5, 980, 18, 105, 200, 548, 320, 121, 3, 30, 43, 356, 22, 16, 570, 121, 3, 809, 6, 35, 287, 39, 64, 36, 19, 28, 658, 10, 1, 978, 253, 615, 162, 356, 5, 168, 1, 64, 7, 50, 170, 12, 444, 25, 16, 23, 5, 26171, 49533, 4, 42, 113, 9, 54, 16, 116, 384, 30, 66, 21, 492815]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import pandas as pd\nimport keras\nfrom sklearn.model_selection import train_test_split\n\n# read in json dataset file from internet\ndataset_url \u003d \u0027http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\u0027\njson_file \u003d pd.read_json(dataset_url, lines\u003dTrue)\n\n# Function to filter helpfulness values (calculate the percentage of helpfulness from the list of numbers in the dataset)\ndef perc_help(helpful):\n\ttry:\n        # e.g. given [2,3], that means 2/3\n\t\tperc \u003d helpful[0] / helpful[1]\n    # if given [0,0], handle that exception (0/0 is not possible)\n\texcept ZeroDivisionError:\n\t\tperc \u003d 0\n\treturn perc\n\n# Create a new calculated column called perc_help to be used for filtering\njson_file[\u0027perc_help\u0027] \u003d json_file.helpful.apply(perc_help)\n\n# Filter json file to only have review with a helpfulness rating above 50%\ncondensed_dataset \u003d json_file[json_file.perc_help \u003e 0.5]\nprint(condensed_dataset.head())\n\n#extract only reviews from json file\nrev_list \u003d json_file[\u0027reviewText\u0027]\n\n# convert each review to a list of word indices\ntokenizer \u003d keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(rev_list)\ntok_list \u003d tokenizer.texts_to_sequences(rev_list)\n\n# split data into testing and training datasets\ntrain_data, test_data \u003d train_test_split(tok_list, test_size\u003d0.20)\n\nprint(train_data[0])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Load Labels",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "data": {
            "text/plain": "1"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 2
        }
      ],
      "source": "# This can change by making mapping the ratings to a different set of numbers\n# i.e. 3 categories instead of 2 by splitting it from 0.0-1.0 (negative), 2.0-3.0 (neutral), and 4.0-5.0 (positive)\nrate_list \u003d json_file[\u0027overall\u0027]\nlabel_list \u003d []\nfor element in rate_list:\n    if element \u003e 2.0:\n        label_list.append(1)\n    else:\n        label_list.append(0)\n\ntrain_labels, test_labels \u003d train_test_split(label_list, test_size\u003d0.20)\n\ntrain_labels[0]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Limit word index to 10,000",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-3-8c48e867e22b\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m\u003cipython-input-3-8c48e867e22b\u003e\u001b[0m in \u001b[0;36m\u003clistcomp\u003e\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ],
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "output_type": "error"
        }
      ],
      "source": "# max([max(sequence) for sequence in train_data])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Preparing Data",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Vectorize Data",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\n\ndef vectorize_sequences(sequences, dimension\u003d10000):\n    # Create an all-zero matrix of shape (len(sequences), dimension)\n    results \u003d np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] \u003d 1.  # set specific indices of results[i] to 1s\n    return results\n\n# Our vectorized training data\nx_train \u003d vectorize_sequences(train_data)\n# Our vectorized test data\nx_test \u003d vectorize_sequences(test_data)\n\nx_train[0]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Vectorize Labels",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": "y_train \u003d np.asarray(train_labels).astype(\u0027float32\u0027)\ny_test \u003d np.asarray(test_labels).astype(\u0027float32\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Building our network",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Implementing the Network",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from keras import models\nfrom keras import layers\n\nmodel \u003d models.Sequential()\nmodel.add(layers.Dense(16, activation\u003d\u0027relu\u0027, input_shape\u003d(10000,)))\nmodel.add(layers.Dense(16, activation\u003d\u0027relu\u0027))\nmodel.add(layers.Dense(1, activation\u003d\u0027softmax\u0027))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Configure with optimizer and loss function",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "model.compile(optimizer\u003d\u0027rmsprop\u0027,\n              loss\u003d\u0027mean_squared_error\u0027,\n              metrics\u003d[\u0027accuracy\u0027])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Validating the approach",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Create Validation set",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "x_val \u003d x_train[:10000]\npartial_x_train \u003d x_train[10000:]\n\ny_val \u003d y_train[:10000]\npartial_y_train \u003d y_train[10000:]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Train model and monitor loss and accuracy",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "history \u003d model.fit(partial_x_train,\n                    partial_y_train,\n                    epochs\u003d20,\n                    batch_size\u003d512,\n                    validation_data\u003d(x_val, y_val))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Look at history",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "history_dict \u003d history.history\nhistory_dict.keys()\n### Plot training and validation loss",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\n\nacc \u003d history.history[\u0027acc\u0027]\nval_acc \u003d history.history[\u0027val_acc\u0027]\nloss \u003d history.history[\u0027loss\u0027]\nval_loss \u003d history.history[\u0027val_loss\u0027]\n\nepochs \u003d range(1, len(acc) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, \u0027bo\u0027, label\u003d\u0027Training loss\u0027)\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, \u0027b\u0027, label\u003d\u0027Validation loss\u0027)\nplt.title(\u0027Training and validation loss\u0027)\nplt.xlabel(\u0027Epochs\u0027)\nplt.ylabel(\u0027Loss\u0027)\nplt.legend()\n\nplt.show()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Plot training and validation accuracy",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "plt.clf()   # clear figure\nacc_values \u003d history_dict[\u0027acc\u0027]\nval_acc_values \u003d history_dict[\u0027val_acc\u0027]\n\nplt.plot(epochs, acc, \u0027bo\u0027, label\u003d\u0027Training acc\u0027)\nplt.plot(epochs, val_acc, \u0027b\u0027, label\u003d\u0027Validation acc\u0027)\nplt.title(\u0027Training and validation accuracy\u0027)\nplt.xlabel(\u0027Epochs\u0027)\nplt.ylabel(\u0027Loss\u0027)\nplt.legend()\n\nplt.show()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Train and test a new network from scratch",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "model \u003d models.Sequential()\nmodel.add(layers.Dense(16, activation\u003d\u0027relu\u0027, input_shape\u003d(10000,)))\nmodel.add(layers.Dense(16, activation\u003d\u0027relu\u0027))\nmodel.add(layers.Dense(1, activation\u003d\u0027sigmoid\u0027))\n\nmodel.compile(optimizer\u003d\u0027rmsprop\u0027,\n              loss\u003d\u0027binary_crossentropy\u0027,\n              metrics\u003d[\u0027accuracy\u0027])\n\nmodel.fit(x_train, y_train, epochs\u003d4, batch_size\u003d512)\nresults \u003d model.evaluate(x_test, y_test)\n\nresults",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Using a trained network to generate predictions on new data",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "model.predict(x_test)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}