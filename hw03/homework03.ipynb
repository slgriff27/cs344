{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {}
   },
   "source": [
    "# Homework 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "It is not possible to build a neural network that computes the XOR function. In order to compute this function, it needs to be able to use the linear AND and OR functions together to only accept inputs were one is true and the other isn't instead of also accepting the case when both are true. This requires that the activation function be non-linear, and it would also require back-propogation where it could feed errors back through the system and learn from that. Without these two qualifications, it isn't possible to build a neural network that computes the XOR function because it is not a linear problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "boston_housing Dataset:\n",
      "Dimensions: 2\n",
      "Shape: (506, 14)\n",
      "Data:\n",
      "crim       float64\n",
      "zn         float64\n",
      "indus      float64\n",
      "chas         int64\n",
      "nox        float64\n",
      "rm         float64\n",
      "age        float64\n",
      "dis        float64\n",
      "rad          int64\n",
      "tax          int64\n",
      "ptratio    float64\n",
      "b          float64\n",
      "lstat      float64\n",
      "medv       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the boston_housing dataset\n",
    "boston_housing = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\")\n",
    "boston_housing.head()\n",
    "\n",
    "# print dimensions, shape, and data type of boston_housing dataset\n",
    "print('\\nboston_housing Dataset:')\n",
    "print('Dimensions: ' + str(boston_housing.ndim))\n",
    "print('Shape: ' + str(boston_housing.shape))\n",
    "print('Data:\\n' + str(boston_housing.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of training data examples: 400\n",
      " number of validation data examples: 50\n",
      " number of testing data examples: 56\n",
      "\n",
      "training dataset         \n",
      "\tdimensions: 2         \n",
      "\tshape: (400, 14) \n",
      "\n",
      " validation dataset         \n",
      "\tdimensions: 2         \n",
      "\tshape: (50, 14) \n",
      "\n",
      " testing dataset             \n",
      "\tdimensions: 2             \n",
      "\tshape: (56, 14)\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into training data, validation data, and testing data\n",
    "train_data = boston_housing[:400]\n",
    "validation_data = boston_housing[400:450]\n",
    "test_data = boston_housing[450:]\n",
    "\n",
    "# part 1 - Print the number of training and validation examples\n",
    "print(f'\\nnumber of training data examples: {len(train_data)}\\n',\n",
    "      f'number of validation data examples: {len(validation_data)}\\n',\n",
    "      f'number of testing data examples: {len(test_data)}\\n')\n",
    "\n",
    "# part 2 - Print the rank (i.e., number of axes/dimensions), shape and data type of the examples\n",
    "print(\n",
    "    f'training dataset \\\n",
    "        \\n\\tdimensions: {train_data.ndim} \\\n",
    "        \\n\\tshape: {train_data.shape} \\n\\n',\n",
    "    f'validation dataset \\\n",
    "        \\n\\tdimensions: {validation_data.ndim} \\\n",
    "        \\n\\tshape: {validation_data.shape} \\n\\n',\n",
    "    f'testing dataset \\\n",
    "            \\n\\tdimensions: {test_data.ndim} \\\n",
    "            \\n\\tshape: {test_data.shape}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.131540\n",
       "1      0.094421\n",
       "2      0.094421\n",
       "3      0.075550\n",
       "4      0.075550\n",
       "5      0.075550\n",
       "6      0.094236\n",
       "7      0.088060\n",
       "8      0.086154\n",
       "9      0.079489\n",
       "10     0.082563\n",
       "11     0.084154\n",
       "12     0.096131\n",
       "13     0.114286\n",
       "14     0.120576\n",
       "15     0.119593\n",
       "16     0.119593\n",
       "17     0.126353\n",
       "18     0.141709\n",
       "19     0.141709\n",
       "20     0.141657\n",
       "21     0.134088\n",
       "22     0.135281\n",
       "23     0.131373\n",
       "24     0.122284\n",
       "25     0.120774\n",
       "26     0.114908\n",
       "27     0.120807\n",
       "28     0.120771\n",
       "29     0.126917\n",
       "         ...   \n",
       "476    0.266343\n",
       "477    0.292284\n",
       "478    0.282884\n",
       "479    0.314678\n",
       "480    0.155365\n",
       "481    0.159678\n",
       "482    0.155984\n",
       "483    0.129810\n",
       "484    0.156552\n",
       "485    0.146053\n",
       "486    0.164415\n",
       "487    0.184944\n",
       "488    0.334450\n",
       "489    0.346929\n",
       "490    0.334138\n",
       "491    0.326000\n",
       "492    0.288639\n",
       "493    0.245623\n",
       "494    0.245623\n",
       "495    0.209033\n",
       "496    0.209033\n",
       "497    0.202233\n",
       "498    0.242829\n",
       "499    0.243760\n",
       "500    0.234169\n",
       "501    0.231179\n",
       "502    0.250492\n",
       "503    0.264360\n",
       "504    0.239859\n",
       "505    0.228743\n",
       "Name: nox_work, Length: 506, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synthetic feature: nitrogen oxide concentration on route to work\n",
    "boston_housing[\"nox_work\"] = (boston_housing[\"nox\"] / boston_housing[\"dis\"])\n",
    "boston_housing[\"nox_work\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "This is a feature that tells you what the average nitrogen oxide concentration will be on your way to an employment center in Boston. It will tell how much pollution is in the air because of vehicle exhaust and other such causes. This could potentially be really important for environmentalists who are trying to make Boston a better and more environmentally friendly place to live.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
