a. It may be managing it through the linear regressor model when it defines my_optimizer two times. The first time it has the learning_rate, and the second time it has something about clipping the gradients by their norm. The second declaration of the optimizer might be informing the first and managing the learning rate.

b. Bucketing/binning takes input and converts it into a discrete value that is simpler to understand and categorize. Instead of having an array of numbers that are all over the spectrum, it is an array of smaller numbers that represent categories that the original numbers are in.

c. 

Task #1
def construct_feature_columns():
  """Construct the TensorFlow Feature Columns.

  Returns:
    A set of feature columns
  """ 
  households = tf.feature_column.numeric_column("households")
  longitude = tf.feature_column.numeric_column("longitude")
  latitude = tf.feature_column.numeric_column("latitude")
  housing_median_age = tf.feature_column.numeric_column("housing_median_age")
  median_income = tf.feature_column.numeric_column("median_income")
  rooms_per_person = tf.feature_column.numeric_column("rooms_per_person")
  
  # Divide households into 7 buckets.
  bucketized_households = tf.feature_column.bucketized_column(
    households, boundaries=get_quantile_based_boundaries(
      training_examples["households"], 7))

  # Divide longitude into 10 buckets.
  bucketized_longitude = tf.feature_column.bucketized_column(
    longitude, boundaries=get_quantile_based_boundaries(
      training_examples["longitude"], 10))
  
  # Divide latitude into 10 buckets.
  bucketized_latitude = tf.feature_column.bucketized_column(
    latitude, boundaries=get_quantile_based_boundaries(
      training_examples["latitude"], 10))

  # Divide housing_median_age into 7 buckets.
  bucketized_housing_median_age = tf.feature_column.bucketized_column(
    housing_median_age, boundaries=get_quantile_based_boundaries(
      training_examples["housing_median_age"], 7))
  
  # Divide median_income into 7 buckets.
  bucketized_median_income = tf.feature_column.bucketized_column(
    median_income, boundaries=get_quantile_based_boundaries(
      training_examples["median_income"], 7))
  
  # Divide rooms_per_person into 7 buckets.
  bucketized_rooms_per_person = tf.feature_column.bucketized_column(
    rooms_per_person, boundaries=get_quantile_based_boundaries(
      training_examples["rooms_per_person"], 7))
  
  feature_columns = set([
    bucketized_longitude,
    bucketized_latitude,
    bucketized_housing_median_age,
    bucketized_households,
    bucketized_median_income,
    bucketized_rooms_per_person])
  
  return feature_columns

_ = train_model(
    learning_rate=1.0,
    steps=500,
    batch_size=100,
    feature_columns=construct_feature_columns(),
    training_examples=training_examples,
    training_targets=training_targets,
    validation_examples=validation_examples,
    validation_targets=validation_targets)

RSME: 88.0

This was fairly straightforward as each feature needed to be divided into buckets on its own. They said they were going to be choosing “arbitrary values” to keep the model from becoming too large, however, they only chose two numbers (7 and 10) for the features. I am a bit confused how they chose both of those numbers given that it was presented as something a little more randomized than that.

Task #2
long_x_lat = tf.feature_column.crossed_column(
  set([bucketized_households, bucketized_housing_median_age]), hash_bucket_size=1000)

RSME: 86.04

I used households and housing_median_age as my feature cross. It would be more useful to know about each house in relation to how old the people are living in it since that can usually help determine how much they are making. Younger residents usually don’t make as much money, especially if they are right out of college. However, older residents probably do make more money, and this median age and household feature cross can help with figuring out the general cost of living in any particular group of houses.
